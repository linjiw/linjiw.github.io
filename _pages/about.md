---
layout: about
title: about
permalink: /
subtitle: Ph.D. Student in Computer Science at <a href='https://cs.gmu.edu/'>George Mason University</a>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>RobotiXX Lab</p>
    <p>George Mason University</p>
    <p>Fairfax, VA 22030</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am a Ph.D. student in Computer Science at George Mason University, working under the supervision of **[Dr. Xuesu Xiao](https://cs.gmu.edu/~xiao/)** at the **[RobotiXX Lab](https://robotixx.cs.gmu.edu/)**. Our lab pioneers **adaptive learning paradigms for autonomous robotics**, and my research addresses a fundamental challenge in robotics: how can robots learn complex behaviors as efficiently as humans do, adapting from simple to complex tasks while maintaining robustness in real-world deployments?

My work centers on **Curriculum Learning for Robotics** - developing intelligent systems that learn progressively, much like how humans master skills through structured practice. I believe the future of robotics lies not in hand-crafted solutions, but in **self-improving systems** that can adapt their learning strategies based on performance feedback. This vision has led me to develop two complementary frameworks:

**[Grounded Adaptive Curriculum Learning (GACL)](https://arxiv.org/pdf/2508.02988)** introduces a **teacher-student paradigm** where an informed teacher agent automatically generates training curricula by monitoring student performance in real-time. This approach bridges the gap between simulation and reality by grounding curriculum generation in actual robot capabilities. **[Reward Training Wheels](https://arxiv.org/pdf/2503.15724)** complements this by providing **adaptive auxiliary rewards** that guide robots through challenging learning phases - like training wheels that automatically adjust and eventually disappear as proficiency increases.

My research has been **validated across diverse robotic platforms**:
- **Quadrupedal robots** navigating complex terrains
- **Ground navigation vehicles** in constrained environments  
- **Off-road autonomous vehicles** handling unpredictable dynamics
- **Current research:** Extending to **humanoid robots** for manipulation tasks

This work, resulting in **three papers accepted at IROS 2025** and one in **IEEE RA-L**, demonstrates **24.58% higher success rates** and **50% improved sample efficiency** compared to state-of-the-art methods. Through collaboration with my advisor **Dr. Xuesu Xiao** and renowned researchers including **[Peter Stone](https://www.cs.utexas.edu/~pstone/)** (UT Austin), I am advancing the frontiers of **adaptive curriculum learning** and **decremental dynamics planning** for robust robot autonomy in complex, dynamic environments.

Prior to my Ph.D., I earned my M.Sc. in Mechanical Engineering from Carnegie Mellon University (GPA: 3.94/4.0), where I developed expertise in **3D perception** and **AR-guided robotics**. I also gained industry experience as a **Software Development Engineer Intern at Amazon AWS**, where I built production-grade systems that reduced performance analysis time from 8 hours to 15 minutes.

My vision is to create **robots that learn like we do** - starting simple, building competence, and ultimately mastering complex real-world tasks through intelligent curriculum design. This research has profound implications for **service robotics**, **industrial automation**, and **human-robot collaboration**.

Feel free to explore my [publications](/linjiwang/publications/), [projects](/linjiwang/projects/), and [CV](/linjiwang/cv/) to learn more about my research and experience.
