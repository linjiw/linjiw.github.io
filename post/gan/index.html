<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: August 15, 2025 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.0f229d4b7ebad1917a9a357cba2effab.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Linji (Joey) Wang"><meta name=description content="In this assignment, we implemented two types of GANs - a Deep Convolutional GAN (DCGAN) and a CycleGAN. The DCGAN was trained to generate grumpy cats from random noise, while the CycleGAN was trained to convert between two types of cats (Grumpy and Russian Blue) and between apples and oranges. Both GANs were implemented with data augmentation and differentiable augmentation techniques."><link rel=alternate hreflang=en-us href=https://linjiw.github.io/post/gan/><link rel=canonical href=https://linjiw.github.io/post/gan/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hub02f11719440bf94480d1ab9e24c040b_151872_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hub02f11719440bf94480d1ab9e24c040b_151872_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:image" content="https://linjiw.github.io/post/gan/featured.png"><meta property="og:site_name" content="Linji Wang"><meta property="og:url" content="https://linjiw.github.io/post/gan/"><meta property="og:title" content="When Cats meet GANs | Linji Wang"><meta property="og:description" content="In this assignment, we implemented two types of GANs - a Deep Convolutional GAN (DCGAN) and a CycleGAN. The DCGAN was trained to generate grumpy cats from random noise, while the CycleGAN was trained to convert between two types of cats (Grumpy and Russian Blue) and between apples and oranges. Both GANs were implemented with data augmentation and differentiable augmentation techniques."><meta property="og:image" content="https://linjiw.github.io/post/gan/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2019-02-05T00:00:00+00:00"><meta property="article:modified_time" content="2019-09-05T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://linjiw.github.io/post/gan/"},"headline":"When Cats meet GANs","image":["https://linjiw.github.io/post/gan/featured.png"],"datePublished":"2019-02-05T00:00:00Z","dateModified":"2019-09-05T00:00:00Z","author":{"@type":"Person","name":"Linji (Joey) Wang"},"publisher":{"@type":"Organization","name":"Linji Wang","logo":{"@type":"ImageObject","url":"https://linjiw.github.io/media/icon_hub02f11719440bf94480d1ab9e24c040b_151872_192x192_fill_lanczos_center_3.png"}},"description":"In this assignment, we implemented two types of GANs - a Deep Convolutional GAN (DCGAN) and a CycleGAN. The DCGAN was trained to generate grumpy cats from random noise, while the CycleGAN was trained to convert between two types of cats (Grumpy and Russian Blue) and between apples and oranges. Both GANs were implemented with data augmentation and differentiable augmentation techniques."}</script><title>When Cats meet GANs | Linji Wang</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=cf2bf6beb32d4133b075c3f3e2208511><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Linji Wang</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Linji Wang</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/ai/><span>AI</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/robotics/><span>Robotics</span></a></li><li class=nav-item><a class=nav-link href=/sde/><span>Software</span></a></li><li class=nav-item><a class=nav-link href=/rl/><span>RL</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>When Cats meet GANs</h1><p class=page-subtitle>A Comprehensive Study on DCGANs and CycleGANs with Advanced Augmentation Techniques</p><div class=article-metadata><div><span class=author-highlighted>Linji (Joey) Wang</span></div><span class=article-date>Last updated on
Sep 5, 2019</span>
<span class=middot-divider></span>
<span class=article-reading-time>6 min read</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/project/>Project</a></span></div></div><div class="article-header container featured-image-wrapper mt-4 mb-4" style=max-width:512px;max-height:256px><div style=position:relative><img src=/post/gan/featured_hu4288bdcdb3699d80052a4f5c670366f0_287815_1200x2500_fit_q100_h2_lanczos_3.webp width=512 height=256 alt class=featured-image>
<span class=article-header-caption>DCGAN Results</span></div></div><div class=article-container><div class=article-style><!-- raw HTML omitted --><details class="toc-inpage d-print-none" open><summary class=font-weight-bold>Table of Contents</summary><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#part-1-deep-convolutional-gan>Part 1: Deep Convolutional GAN</a><ul><li><a href=#experiment-with-dcgans>Experiment with DCGANs</a></li></ul></li><li><a href=#part-2-cyclegan>Part 2: CycleGAN</a><ul><li><a href=#data-augmentation>Data Augmentation</a></li><li><a href=#generator>Generator</a></li><li><a href=#experiment-with-cyclegan>Experiment with CycleGAN</a></li></ul></li><li><a href=#bells--whistles>Bells & Whistles</a><ul><li><a href=#implement-and-train-a-diffusion-model>Implement and train a diffusion model</a></li></ul></li><li><a href=#conclusion-1>Conclusion</a></li></ul></nav></details><h2 id=introduction>Introduction</h2><p>In this assignment, we get hands-on experience coding and training GANs. This assignment includes two parts:</p><p>Implementing a Deep Convolutional GAN (DCGAN) to generate grumpy cats from samples of random noise.
Implementing a more complex GAN architecture called CycleGAN for the task of image-to-image translation. We train the CycleGAN to convert between different types of two kinds of cats (Grumpy and Russian Blue) and between apples and oranges.</p><h2 id=part-1-deep-convolutional-gan>Part 1: Deep Convolutional GAN</h2><p>For the first part of this assignment, we implement a slightly modified version of Deep Convolutional GAN (DCGAN).</p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h3 id=experiment-with-dcgans>Experiment with DCGANs</h3><p>We&rsquo;ve been experimenting with different data preprocessing techniques, and we&rsquo;ve found that the choice of preprocessing can have a significant impact on the performance of the GAN. To demonstrate this, we&rsquo;ve included screenshots of the training loss for both the discriminator and generator with two different preprocessing options: basic, deluxe and diff_aug.</p><h4 id=grumpifybprocessed_basic>grumpifyBprocessed_basic</h4><p><figure id=figure-sample-data_preprocessbasic-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_basic/sample-006400.png alt="sample: data_preprocess=basic, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>sample: data_preprocess=basic, iter = 6400</figcaption></figure><figure id=figure-d_fake_loss-data_preprocessbasic-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_basic/D_fake_loss.png alt="D_fake_loss: data_preprocess=basic, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>D_fake_loss: data_preprocess=basic, iter = 6400</figcaption></figure><figure id=figure-d_real_loss-data_preprocessbasic-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_basic/D_real_loss.png alt="D_real_loss: data_preprocess=basic, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>D_real_loss: data_preprocess=basic, iter = 6400</figcaption></figure><figure id=figure-d_total_loss-data_preprocessbasic-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_basic/D_total_loss.png alt="D_total_loss: data_preprocess=basic, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>D_total_loss: data_preprocess=basic, iter = 6400</figcaption></figure><figure id=figure-g_loss-data_preprocessbasic-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_basic/G_loss.png alt="G_loss: data_preprocess=basic, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>G_loss: data_preprocess=basic, iter = 6400</figcaption></figure></p><h4 id=grumpifybprocessed_deluxe>grumpifyBprocessed_deluxe</h4><p><figure id=figure-data_preprocessdeluxe-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe/sample-006400.png alt="data_preprocess=deluxe, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>data_preprocess=deluxe, iter = 6400</figcaption></figure><figure id=figure-d_fake_loss-data_preprocessdeluxe-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe/D_fake_loss.png alt="D_fake_loss: data_preprocess=deluxe, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>D_fake_loss: data_preprocess=deluxe, iter = 6400</figcaption></figure><figure id=figure-d_real_loss-data_preprocessdeluxe-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe/D_real_loss.png alt="D_real_loss: data_preprocess=deluxe, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>D_real_loss: data_preprocess=deluxe, iter = 6400</figcaption></figure><figure id=figure-d_total_loss-data_preprocessdeluxe-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe/D_total_loss.png alt="D_total_loss: data_preprocess=deluxe, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>D_total_loss: data_preprocess=deluxe, iter = 6400</figcaption></figure><figure id=figure-g_loss-data_preprocessdeluxe-iter--6400><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe/G_loss.png alt="G_loss: data_preprocess=deluxe, iter = 6400" loading=lazy data-zoomable></div></div><figcaption>G_loss: data_preprocess=deluxe, iter = 6400</figcaption></figure><figure id=figure-data_preprocessdeluxe-iter--6400-diff_aug--true><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe_diffaug/sample-006400.png alt="data_preprocess=deluxe, iter = 6400, diff_aug = True" loading=lazy data-zoomable></div></div><figcaption>data_preprocess=deluxe, iter = 6400, diff_aug = True</figcaption></figure></p><h4 id=grumpifybprocessed_deluxe_diffaug>grumpifyBprocessed_deluxe_diffaug</h4><p><figure id=figure-d_fake_loss-data_preprocessdeluxe-iter--6400-diff_aug--true><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe_diffaug/D_fake_loss.png alt="D_fake_loss: data_preprocess=deluxe, iter = 6400, diff_aug = True" loading=lazy data-zoomable></div></div><figcaption>D_fake_loss: data_preprocess=deluxe, iter = 6400, diff_aug = True</figcaption></figure><figure id=figure-d_real_loss-data_preprocessdeluxe-iter--6400-diff_aug--true><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe_diffaug/D_real_loss.png alt="D_real_loss: data_preprocess=deluxe, iter = 6400, diff_aug = True" loading=lazy data-zoomable></div></div><figcaption>D_real_loss: data_preprocess=deluxe, iter = 6400, diff_aug = True</figcaption></figure><figure id=figure-d_total_loss-data_preprocessdeluxe-iter--6400-diff_aug--true><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe_diffaug/D_total_loss.png alt="D_total_loss: data_preprocess=deluxe, iter = 6400, diff_aug = True" loading=lazy data-zoomable></div></div><figcaption>D_total_loss: data_preprocess=deluxe, iter = 6400, diff_aug = True</figcaption></figure><figure id=figure-g_loss-data_preprocessdeluxe-iter--6400-diff_aug--true><div class="d-flex justify-content-center"><div class=w-100><img src=./data/grumpifyBprocessed_deluxe_diffaug/G_loss.png alt="G_loss: data_preprocess=deluxe, iter = 6400, diff_aug = True" loading=lazy data-zoomable></div></div><figcaption>G_loss: data_preprocess=deluxe, iter = 6400, diff_aug = True</figcaption></figure></p><h4 id=results-analysis>Results analysis</h4><table><thead><tr><th>Data Preprocessing</th><th>Discriminator Loss</th><th>Generator Loss</th><th>Convergence Rate</th><th>Stability</th></tr></thead><tbody><tr><td>Basic</td><td>Slow decrease, potential instability</td><td>Fluctuates, struggles to generate realistic images</td><td>Slow</td><td>Less stable</td></tr><tr><td>Deluxe</td><td>Faster decrease, more effective at differentiation</td><td>Converges more quickly, learns from more varied examples</td><td>Faster</td><td>More stable</td></tr><tr><td>Differential Augmentations</td><td>Even faster decrease, more effective at differentiation</td><td>Faster generation of diverse and realistic images</td><td>Fastest</td><td>Most stable</td></tr></tbody></table><p>The table above highlights the key differences in the loss curves for a DCGAN trained with different data preprocessing techniques. Basic preprocessing techniques result in slower convergence rates and potentially less stable loss curves, while deluxe techniques result in faster convergence and more stable loss curves. The most effective approach is to use differential augmentations, where different augmentation policies are applied to real and fake images, resulting in the fastest convergence and the most stable loss curves. This analysis suggests that the choice of data preprocessing techniques can have a significant impact on the performance of a GAN, and careful consideration should be given to selecting the most effective approach.</p><h2 id=part-2-cyclegan>Part 2: CycleGAN</h2><p>Implemented the CycleGAN architecture.</p><h3 id=data-augmentation>Data Augmentation</h3><p>Set the &ndash;data_preprocess flag to deluxe.</p><h3 id=generator>Generator</h3><p>Implemented the generator architecture by completing the <strong>init</strong> method of the CycleGenerator class in models.py.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h3 id=experiment-with-cyclegan>Experiment with CycleGAN</h3><!-- raw HTML omitted --><h4 id=cat_10deluxe_instance_dc_cycle_naive>cat_10deluxe_instance_dc_cycle_naive</h4><table><thead><tr><th style=text-align:center>Title</th><th style=text-align:center>Image</th></tr></thead><tbody><tr><td style=text-align:center>sample X to Y</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_dc_cycle_naive/sample-001000-X-Y.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>sample Y to X</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_dc_cycle_naive/sample-001000-Y-X.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_fake_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_dc_cycle_naive/D_fake_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_real_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_dc_cycle_naive/D_real_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_X_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_dc_cycle_naive/D_X_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_Y_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_dc_cycle_naive/D_Y_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>G_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_dc_cycle_naive/G_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr></tbody></table><!-- raw HTML omitted --><h4 id=cat_10deluxe_instance_patch_cycle_naive>cat_10deluxe_instance_patch_cycle_naive</h4><table><thead><tr><th style=text-align:center>Title</th><th style=text-align:center>Image</th></tr></thead><tbody><tr><td style=text-align:center>sample X to Y</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive/sample-001000-X-Y.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>sample Y to X</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive/sample-001000-Y-X.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_fake_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive/D_fake_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_real_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive/D_real_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_X_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive/D_X_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_Y_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive/D_Y_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>G_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive/G_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr></tbody></table><!-- raw HTML omitted --><h4 id=cat_10deluxe_instance_patch_cycle_naive_cycle>cat_10deluxe_instance_patch_cycle_naive_cycle</h4><table><thead><tr><th style=text-align:center>Title</th><th style=text-align:center>Image</th></tr></thead><tbody><tr><td style=text-align:center>sample X to Y</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle/sample-001000-X-Y.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>sample Y to X</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle/sample-001000-Y-X.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_fake_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle/D_fake_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_real_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle/D_real_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_X_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle/D_X_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_Y_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle/D_Y_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>G_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle/G_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr></tbody></table><!-- raw HTML omitted --><h4 id=cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug>cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug</h4><table><thead><tr><th style=text-align:center>Title</th><th style=text-align:center>Image</th></tr></thead><tbody><tr><td style=text-align:center>sample X to Y</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug/sample-010000-X-Y.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>sample Y to X</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug/sample-010000-Y-X.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_fake_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug/D_fake_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_real_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug/D_real_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_X_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug/D_X_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_Y_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug/D_Y_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>G_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/cat_10deluxe_instance_patch_cycle_naive_cycle_diffaug/G_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr></tbody></table><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id=apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug>apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug</h4><table><thead><tr><th style=text-align:center>Title</th><th style=text-align:center>Image</th></tr></thead><tbody><tr><td style=text-align:center>sample X to Y</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug/sample-010000-X-Y.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>sample Y to X</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug/sample-010000-Y-X.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_fake_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug/D_fake_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_real_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug/D_real_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_X_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug/D_X_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>D_Y_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug/D_Y_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>G_loss</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/apple2orange_10deluxe_instance_patch_cycle_naive_cycle_diffaug/G_loss.png alt loading=lazy data-zoomable></div></div></figure></td></tr></tbody></table><!-- raw HTML omitted --><h4 id=observations>Observations:</h4><p>We observed that the results with the cycle-consistency loss were better than the results without it. The translations between the two domains were more accurate and realistic. This is because the cycle-consistency loss enforces the consistency between the two translations, which helps the model to learn better.</p><p>We also observed that the DCDiscriminator resulted in better quality translations than the PatchDiscriminator. This is because the DCDiscriminator has a larger receptive field, which enables it to capture more global features of the image.</p><h4 id=conclusion>Conclusion:</h4><p>In conclusion, we have trained CycleGAN from scratch with and without the cycle-consistency loss, and have compared the results using the DCDiscriminator and the PatchDiscriminator. We have observed that the cycle-consistency loss and the DCDiscriminator resulted in better quality translations between the two domains. These observations can help in improving the translation quality between different domains in image processing applications.</p><h2 id=bells--whistles>Bells & Whistles</h2><h3 id=implement-and-train-a-diffusion-model>Implement and train a diffusion model</h3><h4 id=training-diffusion-models-with-hugging-faces-diffusers>Training Diffusion Models with Hugging Face&rsquo;s Diffusers</h4><h4 id=introduction-1>Introduction</h4><p>In this project, we train a simple diffusion model using the Hugging Face&rsquo;s Diffusers library. Diffusion models have become state-of-the-art generative models in recent times.</p><h4 id=key-parts-of-the-code>Key Parts of the Code</h4><h5 id=configuration>Configuration:</h5><p>We define a &lsquo;TrainingConfig&rsquo; class that holds all the training hyperparameters.
Hyperparameters include &lsquo;image_size&rsquo;, &rsquo;train_batch_size&rsquo;, &rsquo;eval_batch_size&rsquo;, &rsquo;num_epochs&rsquo;, &lsquo;gradient_accumulation_steps&rsquo;, &rsquo;learning_rate&rsquo;, and &rsquo;lr_warmup_steps&rsquo;, among others.</p><h5 id=data-preprocessing>Data Preprocessing:</h5><p>We use the datasets library to load our dataset and apply data transformations.
The dataset is preprocessed using the transforms.Compose function from torchvision.
The dataset is then transformed on-the-fly during training.</p><h5 id=model-definition>Model Definition:</h5><p>We define our model using the &lsquo;UNet2DModel&rsquo; class from the diffusers library.
The model has various hyperparameters such as &lsquo;sample_size&rsquo;, &lsquo;in_channels&rsquo;, &lsquo;out_channels&rsquo;, &rsquo;layers_per_block&rsquo;, &lsquo;block_out_channels&rsquo;, &lsquo;down_block_types&rsquo;, and &lsquo;up_block_types&rsquo;.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id=training-setup>Training Setup:</h4><p>We use an AdamW optimizer and a cosine learning rate schedule for training.
We use the DDPMPipeline class from the diffusers library for end-to-end inference during evaluation.
The training function train_loop is defined, which includes gradient accumulation, mixed precision training, and multi-GPU or TPU training using the Accelerator class from the accelerate library.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><p>We use the &rsquo;notebook_launcher&rsquo; function from the accelerate library to launch the training from the notebook.</p><h4 id=key-functions>Key Functions</h4><p><em>transform(examples)</em>: Applies the image transformations on the fly during training.
<em>evaluate(config, epoch, pipeline)</em>: Generates a batch of sample images during evaluation and saves them as a grid to the disk.
<em>train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler)</em>: The main training loop, which includes the forward diffusion process, loss calculation, and backpropagation.</p><h4 id=diffusion-results>Diffusion Results</h4><table><thead><tr><th style=text-align:center>Title</th><th style=text-align:center>Image</th></tr></thead><tbody><tr><td style=text-align:center>Apple</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/difussion/apple.png alt loading=lazy data-zoomable></div></div></figure></td></tr><tr><td style=text-align:center>Cat</td><td style=text-align:center><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./data/difussion/cat.png alt loading=lazy data-zoomable></div></div></figure></td></tr></tbody></table><p>The quality of the generated images and how well the DCGAN has captured the main differences between the two domains depend on factors such as the quality of the training data, hyperparameters used during training, and complexity of image domains. If the diffusion results look unrealistic compared to the DCGAN results, it could be due to factors such as dataset quality, model complexity, hyperparameter tuning, or training time. Further analysis and experimentation would be necessary to pinpoint the specific reason for the difference in image quality.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h2 id=conclusion-1>Conclusion</h2><p>This report presents our implementation of DCGAN and CycleGAN for various image generation tasks. Through these experiments, we have observed the impact of data augmentation and differentiable augmentation on the training process and final results. We have also seen the capabilities of CycleGAN in generating realistic images for domain-to-domain translation tasks, such as converting Grumpy cats to Russian Blue cats and vice versa, and converting apples to oranges and vice versa.</p></div><div class=article-tags><a class="badge badge-light" href=/tag/computer-vision/>Computer Vision</a>
<a class="badge badge-light" href=/tag/image-generation/>Image Generation</a>
<a class="badge badge-light" href=/tag/deep-learning/>Deep Learning</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Flinjiw.github.io%2Fpost%2Fgan%2F&text=When+Cats+meet+GANs" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Flinjiw.github.io%2Fpost%2Fgan%2F&t=When+Cats+meet+GANs" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=When%20Cats%20meet%20GANs&body=https%3A%2F%2Flinjiw.github.io%2Fpost%2Fgan%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Flinjiw.github.io%2Fpost%2Fgan%2F&title=When+Cats+meet+GANs" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=When+Cats+meet+GANs%20https%3A%2F%2Flinjiw.github.io%2Fpost%2Fgan%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Flinjiw.github.io%2Fpost%2Fgan%2F&title=When+Cats+meet+GANs" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://linjiw.github.io/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_huc61a9cf250f63b4f157dbff5a6cdbb31_21867_270x270_fill_q100_lanczos_center.jpg alt="Linji (Joey) Wang"></a><div class=media-body><h5 class=card-title><a href=https://linjiw.github.io/>Linji (Joey) Wang</a></h5><h6 class=card-subtitle>PhD Student in AI & Robotics</h6><ul class=network-icon aria-hidden=true><li><a href=mailto:joewwang@outlook.com><i class="fas fa-envelope"></i></a></li><li><a href=https://www.linkedin.com/in/linjiw/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=https://github.com/linjiw target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=/files/Linji%20Wang%20CV%20site-linji.pdf><i class="ai ai-cv"></i></a></li></ul></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2025 Me. This work is licensed under <!-- raw HTML omitted -->CC BY NC ND 4.0<!-- raw HTML omitted --></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <!-- raw HTML omitted -->Wowchemy<!-- raw HTML omitted --> — the free, <!-- raw HTML omitted -->open source<!-- raw HTML omitted --> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js></script></body></html>