<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts | Linji Wang</title><link>https://linjiw.github.io/project/</link><atom:link href="https://linjiw.github.io/project/index.xml" rel="self" type="application/rss+xml"/><description>Posts</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 05 Feb 2019 00:00:00 +0000</lastBuildDate><image><url>https://linjiw.github.io/media/icon_hub02f11719440bf94480d1ab9e24c040b_151872_512x512_fill_lanczos_center_3.png</url><title>Posts</title><link>https://linjiw.github.io/project/</link></image><item><title>When Cats meet GANs</title><link>https://linjiw.github.io/project/gan/</link><pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate><guid>https://linjiw.github.io/project/gan/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>In this assignment, we get hands-on experience coding and training GANs. This assignment includes two parts:&lt;/p>
&lt;p>Implementing a Deep Convolutional GAN (DCGAN) to generate grumpy cats from samples of random noise.
Implementing a more complex GAN architecture called CycleGAN for the task of image-to-image translation. We train the CycleGAN to convert between different types of two kinds of cats (Grumpy and Russian Blue) and between apples and oranges.&lt;/p>
&lt;h2 id="part-1-deep-convolutional-gan">Part 1: Deep Convolutional GAN&lt;/h2>
&lt;p>For the first part of this assignment, we implement a slightly modified version of Deep Convolutional GAN (DCGAN).&lt;/p>
&lt;h3 id="implement-data-augmentation">Implement Data Augmentation&lt;/h3>
&lt;p>Implemented the deluxe version of data augmentation in &amp;lsquo;data_loader.py&amp;rsquo;.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">elif&lt;/span> opts&lt;span style="color:#f92672">.&lt;/span>data_preprocess &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#39;deluxe&amp;#39;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> load_size &lt;span style="color:#f92672">=&lt;/span> int(&lt;span style="color:#ae81ff">1.1&lt;/span> &lt;span style="color:#f92672">*&lt;/span> opts&lt;span style="color:#f92672">.&lt;/span>image_size)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> osize &lt;span style="color:#f92672">=&lt;/span> [load_size, load_size]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> deluxe_transform &lt;span style="color:#f92672">=&lt;/span> transforms&lt;span style="color:#f92672">.&lt;/span>Compose([
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>Resize(opts&lt;span style="color:#f92672">.&lt;/span>image_size, Image&lt;span style="color:#f92672">.&lt;/span>BICUBIC),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>RandomCrop(opts&lt;span style="color:#f92672">.&lt;/span>image_size),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>RandomHorizontalFlip(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>ToTensor(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>Normalize((&lt;span style="color:#ae81ff">0.5&lt;/span>, &lt;span style="color:#ae81ff">0.5&lt;/span>, &lt;span style="color:#ae81ff">0.5&lt;/span>), (&lt;span style="color:#ae81ff">0.5&lt;/span>, &lt;span style="color:#ae81ff">0.5&lt;/span>, &lt;span style="color:#ae81ff">0.5&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train_transform &lt;span style="color:#f92672">=&lt;/span> deluxe_transform
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="implement-the-discriminator-of-the-dcgan">Implement the Discriminator of the DCGAN&lt;/h3>
&lt;p>(Answer for padding calculation goes here)&lt;/p>
&lt;p>Implemented the architecture by filling in the &amp;lsquo;&lt;strong>init&lt;/strong>&amp;rsquo; and &amp;lsquo;forward&amp;rsquo; method of the &amp;lsquo;DCDiscriminator&amp;rsquo; class in &amp;lsquo;models.py&amp;rsquo;.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> __init__(self, conv_dim&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">64&lt;/span>, norm&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;instance&amp;#39;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> super()&lt;span style="color:#f92672">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv1 &lt;span style="color:#f92672">=&lt;/span> conv(&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">32&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, norm, &lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv2 &lt;span style="color:#f92672">=&lt;/span> conv(&lt;span style="color:#ae81ff">32&lt;/span>, &lt;span style="color:#ae81ff">64&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, norm, &lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv3 &lt;span style="color:#f92672">=&lt;/span> conv(&lt;span style="color:#ae81ff">64&lt;/span>, &lt;span style="color:#ae81ff">128&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, norm, &lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv4 &lt;span style="color:#f92672">=&lt;/span> conv(&lt;span style="color:#ae81ff">128&lt;/span>, &lt;span style="color:#ae81ff">256&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, norm, &lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv5 &lt;span style="color:#f92672">=&lt;/span> conv(&lt;span style="color:#ae81ff">256&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#66d9ef">None&lt;/span>, &lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">forward&lt;/span>(self, x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;Forward pass, x is (B, C, H, W).&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>conv1(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>conv2(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>conv3(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>conv4(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>conv5(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> x&lt;span style="color:#f92672">.&lt;/span>squeeze()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="generator">Generator&lt;/h3>
&lt;p>Implemented the generator of the DCGAN by filling in the &amp;lsquo;&lt;strong>init&lt;/strong>&amp;rsquo; and &amp;lsquo;forward&amp;rsquo; method of the &amp;lsquo;DCGenerator&amp;rsquo; class in &amp;lsquo;models.py&amp;rsquo;.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> __init__(self, noise_size, conv_dim&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">64&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> super()&lt;span style="color:#f92672">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>up_conv1 &lt;span style="color:#f92672">=&lt;/span> conv(&lt;span style="color:#ae81ff">100&lt;/span>, &lt;span style="color:#ae81ff">256&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;instance&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">False&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>up_conv2 &lt;span style="color:#f92672">=&lt;/span> up_conv(&lt;span style="color:#ae81ff">256&lt;/span>, &lt;span style="color:#ae81ff">128&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, stride&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, scale_factor&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, norm&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;instance&amp;#39;&lt;/span>, activ&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>up_conv3 &lt;span style="color:#f92672">=&lt;/span> up_conv(&lt;span style="color:#ae81ff">128&lt;/span>, &lt;span style="color:#ae81ff">64&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, stride&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, scale_factor&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, norm&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;instance&amp;#39;&lt;/span>, activ&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>up_conv4 &lt;span style="color:#f92672">=&lt;/span> up_conv(&lt;span style="color:#ae81ff">64&lt;/span>, &lt;span style="color:#ae81ff">32&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, stride&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, scale_factor&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, norm&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;instance&amp;#39;&lt;/span>, activ&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>up_conv5 &lt;span style="color:#f92672">=&lt;/span> up_conv(&lt;span style="color:#ae81ff">32&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, stride&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, scale_factor&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, norm&lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>, activ&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;tanh&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">forward&lt;/span>(self, z):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Generate an image given a sample of random noise.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Input
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> -----
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> z: BS x noise_size x 1 x 1 --&amp;gt; 16x100x1x1
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Output
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ------
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> out: BS x channels x image_width x image_height --&amp;gt; 16x3x64x64
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> z &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>up_conv1(z)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> z &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>up_conv2(z)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> z &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>up_conv3(z)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> z &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>up_conv4(z)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> z &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>up_conv5(z)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> z
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="training-loop">Training Loop&lt;/h3>
&lt;p>Implemented the training loop for the DCGAN by filling in the indicated parts of the training_loop function in vanilla_gan.py.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># TRAIN THE DISCRIMINATOR&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 1. Compute the discriminator loss on real images&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> opts&lt;span style="color:#f92672">.&lt;/span>use_diffaug:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> D_real_loss &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>mean((D(DiffAugment(real_images, policy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;color,translation,cutout&amp;#39;&lt;/span>, channels_first&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span> )) &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#f92672">**&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> D_real_loss &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>mean((D(real_images) &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#f92672">**&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 2. Sample noise&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> noise &lt;span style="color:#f92672">=&lt;/span> sample_noise(opts&lt;span style="color:#f92672">.&lt;/span>batch_size, opts&lt;span style="color:#f92672">.&lt;/span>noise_size)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 3. Generate fake images from the noise&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fake_images &lt;span style="color:#f92672">=&lt;/span> G(noise)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 4. Compute the discriminator loss on the fake images&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> opts&lt;span style="color:#f92672">.&lt;/span>use_diffaug:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> D_fake_loss &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>mean((D(DiffAugment(fake_images&lt;span style="color:#f92672">.&lt;/span>detach(), policy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;color,translation,cutout&amp;#39;&lt;/span>, channels_first&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span> ))) &lt;span style="color:#f92672">**&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> D_real_loss &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>mean((D(fake_images&lt;span style="color:#f92672">.&lt;/span>detach())) &lt;span style="color:#f92672">**&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> D_total_loss &lt;span style="color:#f92672">=&lt;/span> (D_real_loss &lt;span style="color:#f92672">+&lt;/span> D_fake_loss) &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># update the discriminator D&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> d_optimizer&lt;span style="color:#f92672">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> D_total_loss&lt;span style="color:#f92672">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> d_optimizer&lt;span style="color:#f92672">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># TRAIN THE GENERATOR&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 1. Sample noise&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> noise &lt;span style="color:#f92672">=&lt;/span> sample_noise(opts&lt;span style="color:#f92672">.&lt;/span>batch_size, opts&lt;span style="color:#f92672">.&lt;/span>noise_size)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 2. Generate fake images from the noise&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fake_images &lt;span style="color:#f92672">=&lt;/span> G(noise)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 3. Compute the generator loss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> opts&lt;span style="color:#f92672">.&lt;/span>use_diffaug:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> G_loss &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>mean((D(DiffAugment(fake_images, policy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;color,translation,cutout&amp;#39;&lt;/span>, channels_first&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span> ))&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#f92672">**&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> G_loss &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>mean((D(fake_images)&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#f92672">**&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="differentiable-augmentation">Differentiable Augmentation&lt;/h4>
&lt;p>(Discussion of results with and without applying differentiable augmentations, and the difference between two augmentation schemes in terms of implementation and effects)&lt;/p>
&lt;h3 id="experiment-with-dcgans">Experiment with DCGANs&lt;/h3>
&lt;p>INSERT IMAGE: Screenshots of discriminator and generator training loss with &amp;ndash;data_preprocess=basic, &amp;ndash;data_preprocess=deluxe.&lt;/p>
&lt;p>(Brief explanation of what the curves should look like if GAN manages to train)&lt;/p>
&lt;p>INSERT IMAGE: With &amp;ndash;data_preprocess=deluxe and differentiable augmentation enabled, show one of the samples from early in training (e.g., iteration 200) and one of the samples from later in training, and give the iteration number for those samples.&lt;/p>
&lt;p>(Brief comment on the quality of the samples, and in what way they improve through training)&lt;/p>
&lt;h2 id="part-2-cyclegan">Part 2: CycleGAN&lt;/h2>
&lt;p>Implemented the CycleGAN architecture.&lt;/p>
&lt;h3 id="data-augmentation">Data Augmentation&lt;/h3>
&lt;p>Set the &amp;ndash;data_preprocess flag to deluxe.&lt;/p>
&lt;h3 id="generator-1">Generator&lt;/h3>
&lt;p>Implemented the generator architecture by completing the &lt;strong>init&lt;/strong> method of the CycleGenerator class in models.py.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> __init__(self, conv_dim&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">64&lt;/span>, init_zero_weights&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>, norm&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;instance&amp;#39;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> super()&lt;span style="color:#f92672">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># # 1. Define the encoder part of the generator&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv1 &lt;span style="color:#f92672">=&lt;/span> conv(&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">32&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, norm, &lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv2 &lt;span style="color:#f92672">=&lt;/span> conv(&lt;span style="color:#ae81ff">32&lt;/span>, &lt;span style="color:#ae81ff">64&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, norm, &lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># # 2. Define the transformation part of the generator&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>resnet_block &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Sequential(ResnetBlock(conv_dim &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">64&lt;/span>, norm &lt;span style="color:#f92672">=&lt;/span> norm, activ &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ResnetBlock(conv_dim &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">64&lt;/span>, norm &lt;span style="color:#f92672">=&lt;/span> norm, activ &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ResnetBlock(conv_dim &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">64&lt;/span>, norm &lt;span style="color:#f92672">=&lt;/span> norm, activ &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>),)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># # 3. Define the decoder part of the generator&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>up_conv1 &lt;span style="color:#f92672">=&lt;/span> up_conv(&lt;span style="color:#ae81ff">64&lt;/span>, &lt;span style="color:#ae81ff">32&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, stride&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, scale_factor&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, norm&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;instance&amp;#39;&lt;/span>, activ&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;relu&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>up_conv2 &lt;span style="color:#f92672">=&lt;/span> up_conv(&lt;span style="color:#ae81ff">32&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, stride&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, scale_factor&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, norm&lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>, activ&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;tanh&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">forward&lt;/span>(self, x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Generate an image conditioned on an input image.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Input
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> -----
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> x: BS x 3 x 32 x 32
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Output
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ------
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> out: BS x 3 x 32 x 32
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>conv1(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>conv2(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>resnet_block(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>up_conv1(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>up_conv2(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> x
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="training-loop-1">Training Loop&lt;/h3>
&lt;p>Implemented the training loop for the CycleGAN by filling in the indicated parts of the training_loop function in cycle_gan.py.&lt;/p>
&lt;h3 id="experiment-with-cyclegan">Experiment with CycleGAN&lt;/h3>
&lt;p>INSERT IMAGE: Two example images of generated Grumpy cats from Russian Blue cats, and two example images of generated Russian Blue cats from Grumpy cats.&lt;/p>
&lt;p>(Brief comment on the quality of the generated images, and whether the CycleGAN has captured the main differences between the two domains)&lt;/p>
&lt;p>INSERT IMAGE: Two example images of generated apples from oranges, and two example images of generated oranges from apples.&lt;/p>
&lt;p>(Brief comment on the quality of the generated images, and whether the CycleGAN has captured the main differences between the two domains)&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>This report presents our implementation of DCGAN and CycleGAN for various image generation tasks. Through these experiments, we have observed the impact of data augmentation and differentiable augmentation on the training process and final results. We have also seen the capabilities of CycleGAN in generating realistic images for domain-to-domain translation tasks, such as converting Grumpy cats to Russian Blue cats and vice versa, and converting apples to oranges and vice versa.&lt;/p></description></item></channel></rss>