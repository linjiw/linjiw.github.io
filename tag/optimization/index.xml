<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Optimization | Linji Wang</title><link>https://linjiw.github.io/tag/optimization/</link><atom:link href="https://linjiw.github.io/tag/optimization/index.xml" rel="self" type="application/rss+xml"/><description>Optimization</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 05 Feb 2019 00:00:00 +0000</lastBuildDate><image><url>https://linjiw.github.io/media/icon_hub02f11719440bf94480d1ab9e24c040b_151872_512x512_fill_lanczos_center_3.png</url><title>Optimization</title><link>https://linjiw.github.io/tag/optimization/</link></image><item><title>Colorizing the Prokudin-Gorskii Photo Collection</title><link>https://linjiw.github.io/post/colorizing-the-prokudin-gorskii-photo-collectiontickets/</link><pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate><guid>https://linjiw.github.io/post/colorizing-the-prokudin-gorskii-photo-collectiontickets/</guid><description>&lt;!-- raw HTML omitted -->
&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table of Contents&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#overview">Overview&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#matching-metric">Matching Metric&lt;/a>&lt;/li>
&lt;li>&lt;a href="#efficiency">Efficiency&lt;/a>&lt;/li>
&lt;li>&lt;a href="#bells--whistles">Bells &amp;amp; Whistles&lt;/a>&lt;/li>
&lt;li>&lt;a href="#extra-credit">Extra Credit&lt;/a>&lt;/li>
&lt;li>&lt;a href="#final-results">Final Results&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;h1 id="colorizing-the-prokudin-gorskii-photo-collection">Colorizing the Prokudin-Gorskii Photo Collection&lt;/h1>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>This project requires you to use image processing techniques to create a color image from the digitized Prokudin-Gorskii glass plate photographs, with the goal of producing an image with as few visual artifacts as possible. A digital picture of a glass plate, with its three channels arranged from top to bottom as BGR (see Figure 1), serves as the process&amp;rsquo;s input. Our task is to isolate the three channels and properly align them.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/cathedral.jpg" alt="cathedral" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 1. Digitized Glass Plate: Cathedral&lt;/p>
&lt;h3 id="matching-metric">Matching Metric&lt;/h3>
&lt;p>Image matching means to manipulate image to ensure the best results for your similarity metrics. Thus, it is important to choose an efficient and accurate image matching metrics. For this assignment, I explored Sum of Squared Differences (SSD) and Normalized Cross Correlation (NCC) functions. The objective is to maximize or minimize one of these functions by searching and manipulating the images.&lt;/p>
&lt;p>&lt;strong>Sum of Squared Differences&lt;/strong> SSD is calculated based on the following equation:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/ssd.png" alt="ssd" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>where &lt;em>I&lt;/em> and &lt;em>H&lt;/em> are function of two images and x,y are pixels positions.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/11_13PM_February_14_2023/cathedral.jpg_square_limit25_CROPFalse_CannyTrue_PyramidFalse_CMEASFalse_methodSSD_shift[[0,%20-25],[7,%20-25]]_time_cost%202.1364333629608154.jpg" alt="cathedral_ssd" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 2. Cathedral: SSD, Shift:[0, -25],[7, -25] time cost: 2.13s&lt;/p>
&lt;p>&lt;strong>Normalized Cross Correlation&lt;/strong> NNC is calculated based on the following equation:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/ncc.png" alt="ncc" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>where \mu I and\mu H are the luminance of each image.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/11_13PM_February_14_2023/cathedral.jpg_square_limit25_CROPFalse_CannyTrue_PyramidFalse_CMEASFalse_methodNCC_shift%5B%5B0%2C%20-25%5D%2C%5B7%2C%20-25%5D%5D_time_cost%209.591359376907349.jpg" alt="cathedral_ncc" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 3. Cathedral: NCC, Shift:[0, -25],[7, -25] time cost: 9.59s&lt;/p>
&lt;h3 id="efficiency">Efficiency&lt;/h3>
&lt;p>In the above implementation, we construct two for loops to search for the best position in a small window. Comparing and searching image in a small image might work; however, it will take minutes to process a 3500 by 3500 image. We need additional algorithms to pursue efficiency:&lt;/p>
&lt;p>&lt;strong>Image Pyramid Search&lt;/strong> This is an efficient search algorithm that generally yields good results in less than 60 seconds for high resolution imagesâ€”up to 9000 pixels. As mentioned above, this algorithm scales down the image by &lt;em>scale_factor&lt;/em> times, being &lt;em>scale_factor&lt;/em> an automated parameter based on the input image resolution. Given an initial window search, the algorithm searches from coarse to fine images, within the reduced window size, which decreases by a hyperparameter of &lt;em>window_size&lt;/em> as the images become larger.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/pyramid.jpg" alt="pyramid" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Let&amp;rsquo;s first see how long will it take if we process a 3000 by 3000 image without pyramid search.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit50_CROPFalse_CannyFalse_PyramidFalse_searchFalse_methodSSD.jpg" alt="train_pyramid" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 4. Train: SSD w/o Pyramid, time cost: 1857s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit50_CROPFalse_CannyFalse_PyramidFalse_searchFalse_methodNCC.jpg" alt="train_pyramid_ncc" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 5. Train: NCC w/o Pyramid, time cost: 4486s&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Let&amp;rsquo;s apply the pyramid search to see how it affect the searching.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPFalse_CannyFalse_PyramidTrue_searchFalse_methodSSD.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 6. Train: SSD with Pyramid, time cost: 19.03s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPFalse_CannyFalse_PyramidTrue_searchFalse_methodNCC.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 7. Train: NCC with Pyramid, time cost: 39.41s&lt;/p>
&lt;p>Wow, I believe that is a huge performance increase. But the image quality seems not good enough. We will introduce a few of methods in the following part.&lt;/p>
&lt;p>The following are the results with the Pyramid method.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;h3 id="bells--whistles">Bells &amp;amp; Whistles&lt;/h3>
&lt;p>&lt;strong>Auto Border Crop&lt;/strong>&lt;/p>
&lt;p>The borders seem very annoying: 1. They don&amp;rsquo;t contribute to the final results. 2. They can even mess our matching metric.&lt;/p>
&lt;p>Let&amp;rsquo;s try to build a simple border corp algo to handle it.&lt;/p>
&lt;ul>
&lt;li>
&lt;ol>
&lt;li>Define what is a border. Border usually is a long vertical or horizontal distinction between two parts. We can use this attribute as a start.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;ol start="2">
&lt;li>Detect the distinctions. Since the distinction is a huge difference between two parts, they can surely be detected by the edge detector. We utilize Canny Edge Detector for this problem, and define the longgest horizontal/vertical edge as the border. If the edge counts more than 90% of the height or width, we define it as the border and use the ratio as the crop ratio.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>Let&amp;rsquo;s see some images after we implementing the auto border crop.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPTrue_CannyFalse_PyramidTrue_searchFalse_methodSSD.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 18. Train: SSD with Pyramid, CROP, time cost: 34.05s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPTrue_CannyFalse_PyramidTrue_searchFalse_methodNCC.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 19. Train: NCC with Pyramid, CROP, time cost: 44.67s&lt;/p>
&lt;p>The border got cropped before and after the image matching to ensure a clean image. However, the channels are still not matched very well.&lt;/p>
&lt;p>&lt;strong>Edge Detector&lt;/strong>&lt;/p>
&lt;p>Maybe pixel intensity is not enough for the matching, other features like edges are also important. This time, we use Canny edges for SSD and NCC for image matching.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchFalse_methodSSD.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 20. Train: SSD with Pyramid, CROP, Canny, time cost: 18.30s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchFalse_methodNCC.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 21. Train: NCC with Pyramid, CROP, Canny, time cost: 43.35s&lt;/p>
&lt;h3 id="extra-credit">Extra Credit&lt;/h3>
&lt;p>&lt;strong>Evolution Method: Covariance matrix adaptation evolution strategy (CMA-ES)&lt;/strong> The Exhaustive Search can only work for small images and small window size, due to its time complexity of O(windowsize)^2. I propose a novel optimization approach to search the best alignment with CMA-ES. This black-box optimization algorithm consists on treating the search space as a multivariate Gaussian, with varying mean and covariance matrix. The algorithm starts with a population P, initial x and y movement, and initial covariance. We select elites by keeping a fraction of the population of 10% at each iteration, and noise epsilon is added to covariance at each step. We let the algorithm run for several iterations based on image size and set an initial Gaussian variance corroesponding to the windowsize. We optimize using the following equations:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/evolutionsearch.png" alt="evolutionsearch" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Let&amp;rsquo;s see this cool GIF to have an idea how the evolution method find the optimal values.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/CMEASanime.gif" alt="CMEASanime" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 22. CMEAS parameter update process&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/IMGMOVEanime.gif" alt="IMGMOVEanime" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 23. CMEAS image update process&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodSSD.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 24. Train: SSD with Pyramid, Canny, CMEAS, CROP, time cost: 12.89s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 25. Train: NCC with Pyramid, Canny, CMEAS, CROP, time cost: 25.77s&lt;/p>
&lt;p>The CMEAS Evolution method brings 35% performance increase with more clear results.&lt;/p>
&lt;h3 id="final-results">Final Results&lt;/h3>
&lt;p>![cathedral](./data/cathedral.jpg_square_limit10_CROPTrue_CannyTrue_PyramidTrue_CMEASTrue_methodNCC_shift[[5, 2],[12, 1]]_time_cost 1.9317255020141602.jpg)&lt;/p>
&lt;p>Figure 26. cathedral: shift[[5, 2],[12, 1]]_time_cost 1.93s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/emir.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="emir" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 27. emir: shift[[38, 16],[91, 18]]_time_cost 31.65s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/harvesters.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="harvesters" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 28. harvesters: shift[[61, 13],[123, 13]]_time_cost 40.10s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/icon.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="icon" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 29. icon: shift[[30, 16],[76, 22]]_time_cost 33.83s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/lady.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="lady" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 30. lady: shift[[52, 7],[120, 4]]_time_cost 31.90s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/self_portrait.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="self_portrait" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 31. self_portrait: shift[[74, 25],[167, 19]]_time_cost 32.29s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/three_generations.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="three_generations" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 32. three_generations: shift[[44, 6],[106, 6]]_time_cost 38.12s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/turkmen.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="turkmen" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 33. turkmen: shift[[56, 20],[105, 21]]_time_cost 34.34s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/village.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="village" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 34. village: shift[[63, 3],[136, 20]]_time_cost 38.50s&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/train.tifsquare_limit1_CROPTrue_CannyTrue_PyramidTrue_searchTrue_methodNCC.jpg" alt="train" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Figure 35. train: shift[[41, 0],[78, 23]]_time_cost 46.49s&lt;/p></description></item><item><title>Gradient Domain Fusion</title><link>https://linjiw.github.io/post/poisson-blending/</link><pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate><guid>https://linjiw.github.io/post/poisson-blending/</guid><description>&lt;!-- raw HTML omitted -->
&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table of Contents&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#gradient-domain-fusion">Gradient Domain Fusion&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#overview">Overview&lt;/a>&lt;/li>
&lt;li>&lt;a href="#toy-problem">Toy Problem&lt;/a>&lt;/li>
&lt;li>&lt;a href="#poisson-blending">Poisson Blending&lt;/a>&lt;/li>
&lt;li>&lt;a href="#mixed-poisson-blending">Mixed Poisson blending&lt;/a>&lt;/li>
&lt;li>&lt;a href="#mixed-poisson-blending-1">Mixed Poisson blending&lt;/a>&lt;/li>
&lt;li>&lt;a href="#color2gray">Color2Gray&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;h2 id="gradient-domain-fusion">Gradient Domain Fusion&lt;/h2>
&lt;p>&lt;em>by Linji Wang, Feb 07, 2023&lt;/em>&lt;/p>
&lt;h3 id="overview">Overview&lt;/h3>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Welcome to our website about Gradient Domain Fusion, a powerful technique that allows for seamless merging of multiple images into a single high-quality output. Our project aims to explore this technique and provide a detailed guide on how to implement it effectively.&lt;br>
Whether you are a professional photographer or a hobbyist looking to take your images to the next level, our website is the perfect resource to learn about and master Gradient Domain Fusion. So, let&amp;rsquo;s get started and unlock the full potential of this exciting technique!&lt;/p>
&lt;h3 id="toy-problem">Toy Problem&lt;/h3>
&lt;p>In this toy example, we&amp;rsquo;re trying to reconstruct an image called &amp;ldquo;v&amp;rdquo; using some information we get from another image called &amp;ldquo;s&amp;rdquo;. Specifically, we&amp;rsquo;re going to use the x and y gradients of the image s, as well as the intensity of one of its pixels.&lt;/p>
&lt;p>Now, you might be wondering what &amp;ldquo;x and y gradients&amp;rdquo; mean. Think of it this way: imagine looking at a picture of a mountain. If you wanted to describe how the brightness of the image changes as you move your eyes across it, you might say something like &amp;ldquo;the brightness gets darker as you move up the mountain, and lighter as you move down.&amp;rdquo; That&amp;rsquo;s kind of what we mean by &amp;ldquo;gradients&amp;rdquo; - they describe how the brightness (or &amp;ldquo;intensity&amp;rdquo;) of an image changes in different directions.&lt;/p>
&lt;p>So, to summarize: we have one image called &amp;ldquo;s&amp;rdquo;, and we&amp;rsquo;re going to use its x and y gradients (which describe how the brightness changes in different directions) and the intensity of one pixel to create a new image called &amp;ldquo;v&amp;rdquo;. The process isn&amp;rsquo;t too complicated, but it&amp;rsquo;s easy to make mistakes, so we&amp;rsquo;re starting with a simple example to make sure we get it right.&lt;/p>
&lt;p>&lt;strong>Results: toy problem&lt;/strong> Left side: Original image; Right side: Reconstructed Image&lt;/p>
&lt;p>--&amp;gt;
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/toy_reconstruction.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="poisson-blending">Poisson Blending&lt;/h3>
&lt;p>The first step in Poisson blending is to identify the target region in the image, which is the area where we want to blend the images together. For example, if we have two images of a person and a background, the target region might be the outline of the person.&lt;/p>
&lt;p>Next, we need to construct blending constraints. The goal of these constraints is to ensure that the blended image looks seamless and natural. We do this by making sure that the brightness or intensity of the target region is consistent with the gradients of the source and target images.&lt;/p>
&lt;p>To create these constraints, we use the gradient of the images. The gradient describes how the brightness or intensity of the image changes in different directions. We create a set of equations that relate the gradient of the target region to the gradients of the source and target images. These equations are based on the observation that the gradient of the target region should be equal to the gradient of the source image in the non-target region, so as to ensure smooth blending.&lt;/p>
&lt;p>Once we have the blending constraints, we need to solve a least squares problem to find the values for each pixel in the target region that satisfy these constraints. The solution involves finding the values that minimize the difference between the gradient of the target region and the gradients of the source and target images, subject to the blending constraints. This can be done using numerical optimization methods.&lt;/p>
&lt;p>Finally, we construct the blended image by copying the pixels from the source image into the target region, adjusting their colors and intensities according to the solution of the linear equations. This creates a smooth transition between the target region and the rest of the image, resulting in a final image that looks natural and seamless.&lt;/p>
&lt;p>In summary, Poisson blending involves identifying the target region, constructing blending constraints based on the gradients of the images, solving a least squares problem to find the values for each pixel in the target region, and then constructing the final image by copying the pixels from the source image and adjusting their colors and intensities. The result is a seamless and natural-looking image.&lt;/p>
&lt;p>&lt;strong>Results: poisson blend&lt;/strong> Left side: Naive Blend; Right side: Poisson Blend&lt;/p>
&lt;p>--&amp;gt;
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_01.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A Bear&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_01_newsource_target_01Blend.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A Bear swimming with a girl in a pool&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_2.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A Whale&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_2_newsource_target_2Blend.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A Whale swimming at the sea of Boston&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_03.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A man&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_03_newsource_target_03Blend.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Mona Lisa with a man&amp;rsquo;s face&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_04.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A cat&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_04_newsource_target_04Blend.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A cat with another cat&amp;rsquo;s face&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_05.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A cat&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_05_newsource_target_05Blend.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A cat with another cat&amp;rsquo;s face&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_06.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A snowman&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_06_newsource_target_06Blend.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A snowman standing at The Mall, CMU&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_07.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A painting&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_07_newsource_target_07Blend.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A painting at College of Fine Arts Lawn, CMU&lt;/p>
&lt;h3 id="mixed-poisson-blending">Mixed Poisson blending&lt;/h3>
&lt;p>To elaborate, Mixed Poisson blending is a variation of Poisson blending that is used to blend images with different color channels or color spaces. The process involves identifying the target region, constructing blending constraints, and solving a least squares problem to find the values for each pixel in the target region.&lt;/p>
&lt;p>The blending constraints are based on the idea that the brightness or intensity of the image should be consistent across the boundary between the target region and the rest of the image. In Mixed Poisson blending, these constraints are constructed by taking the greatest gradient in the image and using it to construct a sparse matrix.&lt;/p>
&lt;p>The sparse matrix is used to solve the least squares problem, which involves finding the values for each pixel in the target region that satisfy the blending constraints. The solution involves using iterative methods to find the optimal solution that minimizes the difference between the gradients of the target region and the greatest gradient of the image, subject to the blending constraints.&lt;/p>
&lt;p>The resulting pixel values are combined to create the final blended image, which maintains the colors and textures of each image while appearing seamless and natural.&lt;/p>
&lt;p>In summary, Mixed Poisson blending is used to blend images with different color channels or color spaces. The blending constraints are constructed using the greatest gradient in the image to create a sparse matrix, which is then used to solve the least squares problem and find the pixel values in the target region. The resulting blended image maintains the colors and textures of each image, while appearing seamless and natural. &lt;strong>Results: Mixed poisson blend&lt;/strong> Left side: Naive Blend; Right side: Mixed Poisson Blend&lt;/p>
&lt;h3 id="mixed-poisson-blending-1">Mixed Poisson blending&lt;/h3>
&lt;p>--&amp;gt;
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_01.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A Bear&lt;/p>
&lt;p>![](./data/source_01_newsource_target_01Mixed Blend.jpg)&lt;/p>
&lt;p>A Bear swimming with a girl in a pool&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_2.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A Whale&lt;/p>
&lt;p>![](./data/source_2_newsource_target_2Mixed Blend.jpg)&lt;/p>
&lt;p>A Whale swimming at the sea of Boston&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_03.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A man&lt;/p>
&lt;p>![](./data/source_03_newsource_target_03Mixed Blend.jpg)&lt;/p>
&lt;p>Mona Lisa with a man&amp;rsquo;s face&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_04.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A cat&lt;/p>
&lt;p>![](./data/source_04_newsource_target_04Mixed Blend.jpg)&lt;/p>
&lt;p>A cat with another cat&amp;rsquo;s face&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_05.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A cat&lt;/p>
&lt;p>![](./data/source_05_newsource_target_05Mixed Blend.jpg)&lt;/p>
&lt;p>A cat with another cat&amp;rsquo;s face&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_06.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A snowman&lt;/p>
&lt;p>![](./data/source_06_newsource_target_06Mixed Blend.jpg)&lt;/p>
&lt;p>A snowman standing at The Mall, CMU&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/source_07.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Source: A painting&lt;/p>
&lt;p>![](./data/source_07_newsource_target_07Mixed Blend.jpg)&lt;/p>
&lt;p>A painting at College of Fine Arts Lawn, CMU&lt;/p>
&lt;h3 id="color2gray">Color2Gray&lt;/h3>
&lt;p>The color2gray problem refers to the challenge of converting a color image to a grayscale image while preserving the essential information. Grayscale images are often used in applications such as printing, where color images may not be necessary or may be too expensive to produce.&lt;/p>
&lt;p>One approach to solving the color2gray problem is to convert the image to the HSV (Hue, Saturation, Value) color space. The HSV color space separates color information into three channels: Hue, Saturation, and Value. The Hue channel represents the color itself, while the Saturation and Value channels represent the intensity of the color.&lt;/p>
&lt;p>In the HSV color space, we can notice the color difference between channels, which can help us to preserve the essential information when converting to grayscale. One technique for converting an HSV image to grayscale is to use Mixed Poisson Blending. This technique involves solving a least squares problem that takes into account the greatest gradient in the image to construct a sparse matrix. The sparse matrix is used to find the values for each pixel in the target region, resulting in a grayscale image that maintains the essential information from the original color image.&lt;/p>
&lt;p>In summary, the color2gray problem refers to the challenge of converting a color image to grayscale while preserving the essential information. In the HSV color space, we can notice the color difference between channels, and Mixed Poisson Blending can be used to solve the color2gray problem while maintaining the essential information.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/colorBlindTest35.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A colorBlindTest image&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./data/rgb2gray_results.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>A Gray colorBlindTest image and its HSV distributions&lt;/p></description></item></channel></rss>